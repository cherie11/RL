{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra : Solve the LunarLander-v2 \n",
    "--------\n",
    "Landing pad is always at coordinates (0,0). Coordinates are the first two numbers in state vector. Reward for moving from the top of the screen to landing pad and zero speed is about 100..140 points. If lander moves away from landing pad it loses reward back. Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points. Each leg ground contact is +10. Firing main engine is -0.3 points each frame. Solved is 200 points. Landing outside landing pad is possible. Fuel is infinite, so an agent can learn to fly and then land on its first attempt. Four discrete actions available: do nothing, fire left orientation engine, fire main engine, fire right orientation engine.\n",
    "\n",
    "------\n",
    "* Using the DQN to solve this problem using the experience relay and fully connected network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 15:37:58,812] Making new env: LunarLander-v2\n",
      "[2017-12-01 15:37:58,873] Clearing 26 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model...\n",
      "INFO:tensorflow:Restoring parameters from ./dqn/model-0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 15:37:59,433] Restoring parameters from ./dqn/model-0.ckpt\n",
      "[2017-12-01 15:37:59,457] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model\n",
      "Episode 9 reward: -230.438692021\n",
      "Episode 19 reward: -233.371149869\n",
      "Episode 29 reward: -254.907113806\n",
      "Episode 39 reward: -302.436482756\n",
      "Episode 49 reward: -202.264671385\n",
      "Episode 59 reward: -278.709826842\n",
      "Episode 69 reward: -245.303093906\n",
      "Episode 79 reward: -219.779164558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 15:38:04,201] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video000100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 89 reward: -188.694865063\n",
      "Episode 99 reward: -207.626461367\n",
      "Episode 109 reward: -231.90454562\n",
      "Episode 119 reward: -289.935099404\n",
      "Episode 129 reward: -251.398033506\n",
      "Episode 139 reward: -219.922521614\n",
      "Episode 149 reward: -206.923378492\n",
      "Episode 159 reward: -245.209141309\n",
      "Episode 169 reward: -427.297580459\n",
      "Episode 179 reward: -84.584070473\n",
      "Episode 189 reward: -167.319780512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 15:39:49,362] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video000200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 199 reward: -85.0803896385\n",
      "Episode 209 reward: -117.406355101\n",
      "Episode 219 reward: -113.805099367\n",
      "Episode 229 reward: -191.348127156\n",
      "Episode 239 reward: -95.6445750564\n",
      "Episode 249 reward: -121.145958965\n",
      "Episode 259 reward: -125.968628342\n",
      "Episode 269 reward: -140.051496929\n",
      "Episode 279 reward: -181.451398339\n",
      "Episode 289 reward: -148.376631589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 15:45:51,042] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video000300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 299 reward: -139.580908981\n",
      "Episode 309 reward: -158.715636661\n",
      "Episode 319 reward: -159.618477876\n",
      "Episode 329 reward: -59.5134346412\n",
      "Episode 339 reward: -79.7185386111\n",
      "Episode 349 reward: -67.260524884\n",
      "Episode 359 reward: -41.7719288129\n",
      "Episode 369 reward: -72.4064824821\n",
      "Episode 379 reward: 5.999027286\n",
      "Episode 389 reward: -53.0883626375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 15:50:37,124] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video000400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 399 reward: 14.7771821092\n",
      "Episode 409 reward: -47.1138182531\n",
      "Episode 419 reward: -71.5366840334\n",
      "Episode 429 reward: -55.928990606\n",
      "Episode 439 reward: -63.1138896811\n",
      "Episode 449 reward: -44.1756897114\n",
      "Episode 459 reward: 6.51802042099\n",
      "Episode 469 reward: -61.6014491135\n",
      "Episode 479 reward: -64.0623648939\n",
      "Episode 489 reward: -101.116359647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 15:55:56,074] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video000500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 499 reward: -88.980538127\n",
      "Episode 509 reward: -117.464364717\n",
      "Episode 519 reward: -106.758656076\n",
      "Episode 529 reward: -120.856939225\n",
      "Episode 539 reward: -89.8910278456\n",
      "Episode 549 reward: -121.952414425\n",
      "Episode 559 reward: -113.515136832\n",
      "Episode 569 reward: -99.5749241339\n",
      "Episode 579 reward: -108.93664597\n",
      "Episode 589 reward: -97.7349597568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 16:02:09,419] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video000600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 599 reward: -105.249276754\n",
      "Episode 609 reward: -103.858382283\n",
      "Episode 619 reward: -89.8024893255\n",
      "Episode 629 reward: -85.4623779937\n",
      "Episode 639 reward: -78.8202517048\n",
      "Episode 649 reward: -92.9287180227\n",
      "Episode 659 reward: -85.7724815431\n",
      "Episode 669 reward: -78.9717820205\n",
      "Episode 679 reward: -95.297575992\n",
      "Episode 689 reward: -66.100500247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 16:08:25,372] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video000700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 699 reward: -64.9480665386\n",
      "Episode 709 reward: -64.8238650142\n",
      "Episode 719 reward: -62.339163966\n",
      "Episode 729 reward: -138.311485839\n",
      "Episode 739 reward: -31.2849545277\n",
      "Episode 749 reward: -63.9078021379\n",
      "Episode 759 reward: -15.2140953326\n",
      "Episode 769 reward: 1.55241984896\n",
      "Episode 779 reward: 25.8937363909\n",
      "Episode 789 reward: -6.79122400605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 16:13:40,677] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video000800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 799 reward: -60.6754503755\n",
      "Episode 809 reward: -49.3285630885\n",
      "Episode 819 reward: 20.8642854434\n",
      "Episode 829 reward: 16.6550259027\n",
      "Episode 839 reward: 113.409572178\n",
      "Episode 849 reward: 41.191105\n",
      "Episode 859 reward: 69.9401897517\n",
      "Episode 869 reward: 167.243331302\n",
      "Episode 879 reward: 73.9742485668\n",
      "Episode 889 reward: -27.2668935736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 16:17:56,878] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video000900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 899 reward: 26.6107909239\n",
      "Episode 909 reward: -30.9307214134\n",
      "Episode 919 reward: 52.6405755982\n",
      "Episode 929 reward: 109.836353229\n",
      "Episode 939 reward: 163.554486761\n",
      "Episode 949 reward: 82.6979136975\n",
      "Episode 959 reward: 140.717299491\n",
      "Episode 969 reward: 60.1953221013\n",
      "Episode 979 reward: 93.5077709919\n",
      "Episode 989 reward: 97.1695959151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 16:21:51,976] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video001000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 999 reward: 108.448302145\n",
      "Saved Model\n",
      "Episode 1009 reward: 145.750795722\n",
      "Episode 1019 reward: 165.209736406\n",
      "Episode 1029 reward: 156.406816356\n",
      "Episode 1039 reward: 160.586128842\n",
      "Episode 1049 reward: 157.801153298\n",
      "Episode 1059 reward: 146.873678252\n",
      "Episode 1069 reward: 170.060834156\n",
      "Episode 1079 reward: 134.884175627\n",
      "Episode 1089 reward: 81.3508771968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 16:25:07,710] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video001100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1099 reward: 110.727823014\n",
      "Episode 1109 reward: 150.088103456\n",
      "Episode 1119 reward: 1.1589110264\n",
      "Episode 1129 reward: -118.464947905\n",
      "Episode 1139 reward: 107.924505174\n",
      "Episode 1149 reward: 145.024974954\n",
      "Episode 1159 reward: 174.603770825\n",
      "Episode 1169 reward: 170.517830784\n",
      "Episode 1179 reward: 139.637480005\n",
      "Episode 1189 reward: 194.885631483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-01 16:28:28,178] Starting new video recorder writing to /Users/cheriewang/Desktop/SRTP/openaigym.video.0.498.video001200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1199 reward: 161.228888989\n",
      "Episode 1209 reward: 193.482345021\n",
      "Episode 1219 reward: 185.625271156\n",
      "Episode 1229 reward: 195.213124099\n",
      "Episode 1239 reward: 192.55192829\n",
      "Episode 1249 reward: 203.801824426\n",
      "Task Complete,reward:  203.801824426\n",
      "Real episode:  1249\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow.contrib.slim as slim\n",
    "from gym.wrappers import Monitor\n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "num_episodes = 1000\n",
    "#Whether capture the video\n",
    "#----------------------------\n",
    "#env = Monitor((env),directory=\"./dqn\",video_callable=lambda count: count % 100 == 0, write_upon_reset=True,force=True)\n",
    "\n",
    "from gym.wrappers import Monitor\n",
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])\n",
    "\n",
    "\n",
    "batch_size = 50 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 5000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 2000 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network\n",
    "\n",
    "\n",
    "class SingleQnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        #We use slim.conv2d to set up our network \n",
    "        self.scalarInput =  tf.placeholder(shape=[None,8],dtype=tf.float32)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()  \n",
    "        W1 = tf.Variable(xavier_init([8,512]))\n",
    "        b1=tf.Variable(0.0,name='b1')\n",
    "        W2 = tf.Variable(xavier_init([512,h_size]))\n",
    "        b2=tf.Variable(0.0,name='b2')\n",
    "        # hidden layers\n",
    "        self.fc1= tf.nn.relu(tf.matmul(self.scalarInput,W1) + b1)\n",
    "        # Q Value layer\n",
    "        self.fc2= tf.nn.relu(tf.matmul(self.fc1,W2)+ b2)\n",
    "        W = tf.Variable(xavier_init([h_size,4]))\n",
    "     \n",
    "        b=tf.Variable(0.0,name='b')\n",
    "       \n",
    "        self.Qout =tf.matmul(slim.flatten( self.fc2),W)+b\n",
    "    \n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,4,dtype=tf.float32)\n",
    "        \n",
    "        predQ=tf.reduce_sum((self.Qout*self.actions_onehot),axis=1)  #advangtage of choosing predicted action\n",
    "        self.loss=tf.reduce_mean(tf.squared_difference(self.targetQ,predQ))      \n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "mainQN = SingleQnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "with tf.device('/gpu:0'):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        if load_model == True:\n",
    "            print('Loading Model...')\n",
    "            ckpt = tf.train.get_checkpoint_state(path)\n",
    "            saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "        for i in range(num_episodes):\n",
    "            episodeBuffer = experience_buffer()\n",
    "            #Reset environment and get first new observation\n",
    "            s = env.reset()\n",
    "   \n",
    "            d = False\n",
    "            rAll = 0\n",
    "            j = 0\n",
    "            #The Q-Network\n",
    "            while j < max_epLength: #If the agent takes longer than 50 moves to reach either of the blocks, end the trial.\n",
    "                j+=1\n",
    "                #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "                if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                    a = np.random.randint(0,4)\n",
    "                else:\n",
    "                    a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.reshape(np.array(s),[-1,8])})[0]\n",
    "                total_steps += 1\n",
    "                s1,r,d,_=env.step(a)\n",
    "         \n",
    "                episodeBuffer.add(np.array([s,a,r,s1,d]).reshape(1,5))\n",
    "\n",
    "                if total_steps > pre_train_steps:\n",
    "                    if e > endE:\n",
    "                        e -= stepDrop\n",
    "\n",
    "                    if total_steps % (update_freq) == 0:\n",
    "\n",
    "\n",
    "                        train_batch=myBuffer.sample(batch_size)\n",
    "                        cur_state=np.vstack(train_batch[:,0])\n",
    "                        action_batch=train_batch[:,1]\n",
    "                        r_batch=train_batch[:,2]\n",
    "                        next_state=np.vstack(train_batch[:,3])\n",
    "\n",
    "                        #select the predicted action\n",
    "                        Qout,predict=sess.run([mainQN.Qout,mainQN.predict],feed_dict={mainQN.scalarInput:next_state})\n",
    "                       \n",
    "                        #calculate Q-values for next state\n",
    "                        #select the value for updating\n",
    "                        Qpredict=Qout[range(batch_size),predict]\n",
    "\n",
    "                        mask= -(train_batch[:,4] - 1)  \n",
    "                        targetQ =r_batch+(y*Qpredict*mask)\n",
    "\n",
    "                        loss,_=sess.run([mainQN.loss,mainQN.updateModel] ,feed_dict={mainQN.scalarInput:cur_state,mainQN.actions:action_batch,mainQN.targetQ:targetQ})\n",
    "                        #if i % 100 == 0:\n",
    "                            #print(loss)\n",
    "                rAll += r\n",
    "                s = s1\n",
    "\n",
    "                if d == True:\n",
    "                    break\n",
    "\n",
    "            myBuffer.add(episodeBuffer.buffer)\n",
    "            jList.append(j)\n",
    "            rList.append(rAll)\n",
    "            \n",
    "            #Periodically save the model. \n",
    "            if i % 1000 == 0:\n",
    "                saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "                print(\"Saved Model\")\n",
    "            if len(rList) % 10 == 0:\n",
    "                print(\"Episode\",i,\"reward:\",np.mean(rList[-10:]))\n",
    "                if(np.mean(rList[-10:])>=200):\n",
    "                    print('Task Complete,reward: ', np.mean(rList[-10:]))\n",
    "                    break\n",
    "        saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "print(\"Real episode: \" ,i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11833d5f8>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104a1fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "\n",
    "%matplotlib inline\n",
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0a4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
